# Linear Regression 
We can divide in simple and multi-variable problems, the simple one is defioned as follow: y = wix + b, The point is mesure the relationshop between two variables, late you'll see how to expand it to many.

The b here, represents the intercept in the y axis, and w the weights, our mission is to find w that enable us to predict unseen values based on its relationshiop.

The objetive of linear regression is to fit the best possible line, based on our data. 

## Multiple Linear Regression
For a problem with 'n' features, we apply a sum at our original (univariete) equation.
![image](https://github.com/user-attachments/assets/57222005-500a-4f54-92c2-6cb6ef60c71d)


## RANSAC (RANdom SAmple Consensus)
[RANSAC](https://en.wikipedia.org/wiki/Random_sample_consensus) works by examining if a value has impact (so it means that its a outliers).

- It fit a model in several samples of data and choose the best model (sample with more inliers will perform better)

![image](https://github.com/user-attachments/assets/9d973ec9-6e95-4413-839f-9e34b2c87f77)

dataset with many outliers

![image](https://github.com/user-attachments/assets/213eec56-be96-452c-b76a-c2ef57b11b1d)

RANSAC in the data, outliers has no effect.


**RANSAC**

RANSAC is an acronimous for RANdom SAmple Consensus, we can use to peform linear regression task when the data have lots of outliers. It works as follow:

- fit a model in a sample of the data
- choose the model model (precisely the sample with less outliers)

To decide if a data point is a outliers or not, the model use the MAD concept, which is how far the datapoint is from the mean, we can adjust out mad. To calculate mad, we do: mean(abs(data-mean(data))

Evan RANSAC is really good with outliers by selecting inliers, there is no guaratee that the model i'll have a good performance on unseen data.

## Evaluating Regression Models
Train a model is half of the problem, as a ml engineer you need assure that your model works on unseen data.

### mini-essay

Evaluate a model is the validation that out model works properly. It brings lots important things, as clarity about how well it'll work on unseen data. Each metrics has it's particulary. We need considerer de proper context and when use one or another.

**mse**

Imagine we are working with mean values in dolors of house prices, the mse (mean squared error) compute the error (y_true - y_predicted) squared.

mae

r2

references
