# Linear Regression 
We can divide in simple and multi-variable problems, the simple one is defioned as follow: y = wix + b, The point is mesure the relationshop between two variables, late you'll see how to expand it to many.

The b here, represents the intercept in the y axis, and w the weights, our mission is to find w that enable us to predict unseen values based on its relationshiop.

The objetive of linear regression is to fit the best possible line, based on our data. 

## Multiple Linear Regression
For a problem with 'n' features, we apply a sum at our original (univariete) equation.
![image](https://github.com/user-attachments/assets/57222005-500a-4f54-92c2-6cb6ef60c71d)



## RANSAC (RANdom SAmple Consensus)
[RANSAC](https://en.wikipedia.org/wiki/Random_sample_consensus) works by examining if a value has impact (so it means that its a outliers).

- It fit a model in several samples of data and choose the best model (sample with more inliers will perform better)

![image](https://github.com/user-attachments/assets/9d973ec9-6e95-4413-839f-9e34b2c87f77)

dataset with many outliers

![image](https://github.com/user-attachments/assets/213eec56-be96-452c-b76a-c2ef57b11b1d)

RANSAC in the data, outliers has no effect.

- mini-essay

**RANSAC**

RANSAC is an acronimous for RANdom SAmple Consensus, we can use to peform linear regression task when the data have lots of outliers. It works as follow:

- fit a model in a sample of the data
- choose the model model (precisely the sample with less outliers)

To decide if a data point is a outliers or not, the model use the MAD concept, which is how far the datapoint is from the mean, we can adjust out mad. To calculate mad, we do: mean(abs(data-mean(data))

Evan RANSAC is really good with outliers by selecting inliers, there is no guaratee that the model i'll have a good performance on unseen data.

## Evaluating Regression Models


### mini-essay
